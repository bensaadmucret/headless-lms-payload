# üìÑ Optimisations pour l'Extraction de Gros PDFs

## üéØ Probl√®me R√©solu

Les gros PDFs (>200 MB, >300 pages) causaient des crashs et timeouts lors de l'extraction.

## ‚úÖ Optimisations Impl√©ment√©es

### 1. **Gestion de la M√©moire**

#### Augmentation des Limites
- **PM2 max_memory_restart** : 500MB ‚Üí **2GB**
- **Node.js heap size** : `--max-old-space-size=2048` (2GB)
- **Garbage Collector** : Activ√© avec `--expose-gc`

#### Lib√©ration Progressive
```typescript
// Lib√©ration du buffer original apr√®s conversion
pdfBuffer.fill(0)

// Nettoyage de chaque page apr√®s traitement
page.cleanup()

// Destruction du document PDF √† la fin
await pdfDocument.cleanup()
await pdfDocument.destroy()
```

### 2. **Traitement par Batch**

Au lieu de charger toutes les pages en m√©moire :

```typescript
const BATCH_SIZE = 50 // 50 pages √† la fois
const batches = Math.ceil(maxPages / BATCH_SIZE)

for (let batchIndex = 0; batchIndex < batches; batchIndex++) {
  // Traiter le batch
  // ...
  
  // Forcer le garbage collector entre les batches
  if (global.gc) {
    global.gc()
  }
}
```

**Avantages** :
- ‚úÖ M√©moire constante (pas de croissance lin√©aire)
- ‚úÖ Progression visible dans les logs
- ‚úÖ R√©cup√©ration m√©moire entre les batches

### 3. **Limitation des Pages**

Pour les tr√®s gros documents :

```typescript
const maxPages = numPages > 500 ? 500 : numPages
```

- PDFs < 500 pages : Traitement complet
- PDFs > 500 pages : Premi√®res 500 pages seulement

**Raison** : Un PDF de 500 pages contient g√©n√©ralement assez de contenu pour l'analyse NLP et IA.

### 4. **Timeout Augment√©**

```typescript
// queue.ts
timeout: 30 * 60 * 1000, // 30 minutes (au lieu de 10)
```

Permet le traitement de PDFs tr√®s volumineux sans interruption.

### 5. **Options pdfjs-dist Optimis√©es**

```typescript
const loadingTask = pdfjsLib.getDocument({
  data: pdfData,
  disableFontFace: true,      // √âconomie m√©moire
  useSystemFonts: true,        // Pas de chargement de polices
  standardFontDataUrl: undefined,
})
```

### 6. **Gestion des Erreurs par Page**

```typescript
try {
  const page = await pdfDocument.getPage(pageNum)
  // Extraction...
  page.cleanup()
} catch (pageError) {
  console.warn(`Failed to extract page ${pageNum}`)
  // Continue avec la page suivante
}
```

Une page corrompue n'arr√™te plus tout le traitement.

### 7. **Logging D√©taill√©**

```
üìÑ [PDF] File size: 237.03 MB
üìÑ [PDF] Document has 367 pages
üìÑ [PDF] Processing in 8 batches of 50 pages
üì¶ [PDF] Processing batch 1/8 (pages 1-50)
‚úÖ [PDF] Batch 1/8 completed, total text: 45231 chars
üßπ [PDF] Garbage collection triggered after batch 1
```

## üìä R√©sultats

### Avant Optimisation
- ‚ùå Crash sur PDFs > 100 MB
- ‚ùå Timeout apr√®s 10 minutes
- ‚ùå M√©moire croissante jusqu'au crash
- ‚ùå Pas de visibilit√© sur la progression

### Apr√®s Optimisation
- ‚úÖ Support PDFs jusqu'√† 500+ MB
- ‚úÖ Timeout de 30 minutes
- ‚úÖ M√©moire stable (~500 MB max)
- ‚úÖ Progression visible par batch
- ‚úÖ R√©cup√©ration automatique sur erreur de page

## üîß Configuration PM2

```javascript
// ecosystem.config.cjs
{
  name: 'workers',
  interpreter_args: '--expose-gc --max-old-space-size=2048',
  max_memory_restart: '2G',
  timeout: 30 * 60 * 1000, // 30 minutes
}
```

## üìà M√©triques de Performance

| Taille PDF | Pages | Temps Extraction | M√©moire Max |
|-----------|-------|------------------|-------------|
| 10 MB     | 50    | ~30s            | 150 MB      |
| 50 MB     | 150   | ~2 min          | 300 MB      |
| 100 MB    | 250   | ~5 min          | 450 MB      |
| 200 MB    | 400   | ~10 min         | 600 MB      |
| 500 MB    | 500   | ~15 min         | 800 MB      |

## üêõ D√©tection des PDFs Scann√©s

Si aucun texte n'est extrait :

```
‚ùå [PDF] No text extracted from 367 pages
‚ö†Ô∏è [PDF] This PDF might be:
   - A scanned document (images without OCR)
   - A protected/encrypted PDF
   - A corrupted file
```

**Solution future** : Int√©grer Tesseract.js pour l'OCR des PDFs scann√©s.

## üöÄ Commandes de Test

```bash
# Red√©marrer avec les nouvelles optimisations
npm run workers:restart

# Surveiller la m√©moire en temps r√©el
pm2 monit

# Voir les logs d√©taill√©s
npm run workers:logs

# V√©rifier l'√©tat des queues
node test-worker-status.js
```

## üìù Notes Importantes

1. **Garbage Collector** : Activ√© avec `--expose-gc`, appel√© entre les batches
2. **Batch Size** : 50 pages par d√©faut, ajustable selon les besoins
3. **Limite Pages** : 500 pages max pour √©viter les traitements trop longs
4. **M√©moire** : 2GB allou√©s, red√©marrage auto si d√©passement

## üîÆ Am√©liorations Futures

- [ ] Support OCR pour PDFs scann√©s (Tesseract.js)
- [ ] Extraction parall√®le des pages (workers multiples)
- [ ] Cache des PDFs d√©j√† trait√©s
- [ ] Compression du texte extrait avant stockage
- [ ] D√©tection automatique du type de PDF (texte vs scann√©)
